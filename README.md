# 🪄 Sign Language Prediction Model

This project is a deep learning-based image classification model that recognizes American Sign Language (ASL) alphabets from RGB images using Convolutional Neural Networks (CNNs) in TensorFlow/Keras.

---

## 📌 Project Description

The model takes colored images of hand gestures representing ASL alphabets and predicts the correct label using a multi-class classification CNN architecture. It has been trained on a dataset of labeled RGB images and saves the trained model in `.h5` format.

---

## 🧠 Model Architecture

- **Input:** 64x64 RGB images
- **Layers:**
  - 2 Convolutional layers with MaxPooling
  - Flatten layer
  - Dense layers with ReLU activation
  - Output layer with Softmax (26 classes)
- **Optimizer:** Adam
- **Loss Function:** Categorical Crossentropy
- **Metric:** Accuracy

---

## ✅ Features
- Built with TensorFlow and Keras
- Uses CNN for image recognition of ASL gestures
- Saves trained model as .h5 file
- Modular codebase for easy upgrades and feature additions

---

## 🙋‍♀️ Author
## Sanya Sharma
- 👩‍💻 MCA Student | Python & ML Enthusiast
- 📧 Email: [sannyasharma.exe@gmail.com](mailto:sannyasharma.exe@gmail.com)  
- 🌐 GitHub: [@sanya-code](https://github.com/sanya-code) 
- 🌎 Website: [with-sanya.streamlit.app](https://with-sanya.streamlit.app)




